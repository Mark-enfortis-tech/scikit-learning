'''
Multivariable linear regression is a type of linear regression where more than one independent variable (feature) is used to 
predict a single dependent variable (target).

ğŸ§® The General Formula
y=Î²0+Î²1x1+Î²2x2+â‹¯+Î²nxn+Îµ


Where:

    y: Dependent variable (what you want to predict)

    x1,x2,â€¦,x1â€‹,x2â€‹,â€¦,xnâ€‹: Independent variables (features)

    Î²0â€‹: Intercept

    Î²1,â€¦,Î²1â€‹,â€¦,Î²nâ€‹: Coefficients (weights for each feature)

    Îµ: Error term (difference between actual and predicted)
    
ğŸ¯ Purpose

To model the relationship between multiple input variables and a single output, and use that relationship to:

    Understand how variables influence the target.

    Predict future outcomes.
    
ğŸ¡ Example

Suppose youâ€™re predicting house prices (y) based on:

    Size in square feet (xâ‚)

    Number of bedrooms (xâ‚‚)

    Age of the house (xâ‚ƒ)

The model might look like:
Price=Î²0+Î²1â‹…Size+Î²2â‹…Bedrooms+Î²3â‹…Age+Îµ

ğŸ“Š When to Use It?

Use multivariable linear regression when:

    You have more than one predictor.

    You want to quantify relationships.

    You assume a linear relationship between predictors and target.

âš ï¸ Assumptions

Like all models, multivariable linear regression makes some assumptions:

    Linearity: The relationship between inputs and output is linear.

    Independence: Observations are independent.

    Homoscedasticity: Constant variance of residuals (errors).

    Normality: Residuals should be roughly normally distributed.

    No multicollinearity: Predictors shouldnâ€™t be too highly correlated with each other (or consider using Ridge/Lasso regression).


'''